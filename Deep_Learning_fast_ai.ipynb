{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOl+V17JPv7mpOgr6kNazio",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AwaisAli37405/Deep_Learning_with_fast_ai/blob/master/Deep_Learning_fast_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsNzuRfjxIWd"
      },
      "outputs": [],
      "source": [
        "from fastai.vision.all import *\n",
        "from fastai.text.all import *\n",
        "from fastai.collab import *\n",
        "from fastai.tabular.all import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U fastprogress fastai"
      ],
      "metadata": {
        "id": "6a05x5uvIw-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In order to use the built in datasets available in fast ai untar_data. It can be downloaded and decompresses using the following line of code:"
      ],
      "metadata": {
        "id": "wrfkmOXc7Qzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = untar_data(URLs.PETS)/'images'\n",
        "# print(path)\n",
        "# path.ls()"
      ],
      "metadata": {
        "id": "iEPIKqUkQSMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IT will download the dataset once and will return the location. Now we will use the factory method that is a great way to get your data quickly ready for training - get image file. It is a fastai function that helps us grab all the image files (recursively) in one folder."
      ],
      "metadata": {
        "id": "cX4ZNqxs7pu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files = get_image_files(path)\n",
        "len(files)\n"
      ],
      "metadata": {
        "id": "H42nm_DNPLbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now to get this data labeled following convention has been adopted in fast.ai. There is an easy way to distinguish: the name of the file begins with a capital for cats, and a lowercased letter for dogs"
      ],
      "metadata": {
        "id": "vtl117818pYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_cat(x): return x[0].isupper()\n"
      ],
      "metadata": {
        "id": "5RHM6SjP8qDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To get our data ready for the model we need to initialize the dataloader object.\n",
        "### There is function in Vision_data of fast_ai that can label the examples using names of the image files imagedataloader.from_name_fucntion"
      ],
      "metadata": {
        "id": "0oe7hx4A9iWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We have passed to this function the directory we’re working in, the files we grabbed, our label_func and one last piece as item_tfms: this is a Transform applied on all items of our dataset that will resize each image to 224 by 224, by using a random crop on the largest dimension to make it a square, then resizing to 224 by 224. If we didn’t pass this, we would get an error later as it would be impossible to batch the items together."
      ],
      "metadata": {
        "id": "YN6zpbL6-HRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dls = ImageDataLoaders.from_name_func(\n",
        "    path, get_image_files(path), valid_pct=0.2, seed=42,\n",
        "    label_func=is_cat, item_tfms=Resize(224))\n",
        "\n"
      ],
      "metadata": {
        "id": "GRbR_fYdH8fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dls.show_batch()"
      ],
      "metadata": {
        "id": "gR6AURp6-cm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Then we can create a Learner, which is a fastai object that combines the data and a model for training, and uses transfer learning to fine tune a pretrained model in just two lines of code:"
      ],
      "metadata": {
        "id": "eP2OQDQH-yyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = vision_learner(dls, resnet34, metrics=error_rate)\n",
        "learn.fine_tune(1)"
      ],
      "metadata": {
        "id": "BJnCwUQCIF1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### If you want to make a prediction on a new image, you can use learn.predict:"
      ],
      "metadata": {
        "id": "DXrJLVxq-4jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn.predict(files[0])"
      ],
      "metadata": {
        "id": "l35xAmJK-0Gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.show_results()"
      ],
      "metadata": {
        "id": "uB3IVEmF--rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to export the models\n",
        "learn.export('model.pkl')"
      ],
      "metadata": {
        "id": "oxFXmkA0lbFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "?vision_learner"
      ],
      "metadata": {
        "id": "xY4Fx_CgBnBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Which Image models are the best?\n",
        "Pytorch has many [image models](https://timm.fast.ai/) around 500. These models are basically the mathemical functions differ on how much time, accuracy and from which family they belong.\n",
        "\n",
        "Ross regularly [benchmarks](https://www.kaggle.com/code/jhoward/which-image-models-are-best/) new models as they are added to timm."
      ],
      "metadata": {
        "id": "aAHeg_aNgU7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timm"
      ],
      "metadata": {
        "id": "Fm2CsMYugj6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timm.list_models() # list all the models in pytorch"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PvDkBQA8kUqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we want to use the covnext model - Search for model architectures by Wildcard\n",
        "timm.list_models('convnext*')"
      ],
      "metadata": {
        "id": "57LU_nE_kXN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "??(vision_learner)\n"
      ],
      "metadata": {
        "id": "pEbS7VWOmfoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normally, models perform calculations using fp32 (Single-Precision), where each number takes up 32 bits of memory. By calling .to_fp16() on your vision_learner, you are telling the model to use Mixed Precision training.\n",
        "$$\n",
        "\\begin{array}{|l|c|c|}\n",
        "\\hline\n",
        "\\textbf{Feature} & \\textbf{FP32 (Standard)} & \\textbf{FP16 (Mixed Precision)} \\\\ \\hline\n",
        "\\text{Memory per value} & \\text{4 Bytes (32 bits)} & \\text{2 Bytes (16 bits)} \\\\ \\hline\n",
        "\\text{Training Speed} & \\text{Baseline} & \\text{Significantly Faster} \\\\ \\hline\n",
        "\\text{VRAM Usage} & \\text{Higher} & \\text{Lower (~50\\% less)} \\\\ \\hline\n",
        "\\text{Hardware Requirement} & \\text{Any GPU} & \\text{Modern GPU (Turing+)} \\\\ \\hline\n",
        "\\end{array}\n",
        "$$"
      ],
      "metadata": {
        "id": "sJ3vR2WdooZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# so if we want to use any of these models with fast-ai vision learner we have to provide it as a string as an input\n",
        "learn = vision_learner(dls, 'convnext_tiny_in22k', metrics=error_rate).to_fp16()\n",
        "learn.fine_tune(1)"
      ],
      "metadata": {
        "id": "pyChC7PjkmdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding the `dls.vocab` Object\n",
        "\n",
        "In fastai, the `dls.vocab` (Vocabulary) acts as the mapping system between human-readable labels and the integer indices used by the neural network.\n",
        "\n",
        "$$\n",
        "\\begin{array}{|l|l|l|}\n",
        "\\hline\n",
        "\\textbf{Property/Method} & \\textbf{Description} & \\textbf{Example Output} \\\\ \\hline\n",
        "\\text{dls.vocab} & \\text{The list of unique class names} & \\text{['black', 'grizzly', 'teddy']} \\\\ \\hline\n",
        "\\text{len(dls.vocab)} & \\text{Total number of classes (output neurons)} & \\text{3} \\\\ \\hline\n",
        "\\text{dls.vocab[i]} & \\text{Find label string at index } i & \\text{'grizzly' (for } i=1\\text{)} \\\\ \\hline\n",
        "\\text{dls.vocab.o2i} & \\text{Dictionary mapping 'Object to Index'} & \\text{\\{'black': 0, 'grizzly': 1, ...\\}} \\\\ \\hline\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "**Key Mathematical Concept:**\n",
        "The final layer of your model outputs a vector $\\mathbf{y}$ of size $N$, where $N = \\text{len(dls.vocab)}$.\n",
        "The probability for class $i$ is calculated such that:\n",
        "$$ P(\\text{class}_i) = \\text{softmax}(\\mathbf{y})_i $$\n",
        "where the index $i$ corresponds exactly to the position in `dls.vocab`."
      ],
      "metadata": {
        "id": "NkjQCnIcpoG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categories  =  learn.dls.vocab"
      ],
      "metadata": {
        "id": "JF95SmcPlRcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(categories) # since we have tewo categories false and true"
      ],
      "metadata": {
        "id": "1xRUCzNMp3IB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now to map them\n",
        "def classify_img(img):\n",
        "    pred, idx, probs = learn.predict(img)\n",
        "    return dict(zip(categories, map(float, probs)))"
      ],
      "metadata": {
        "id": "tm3YrlXQp4_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classify_img(files[100])"
      ],
      "metadata": {
        "id": "oFaVE7LGqMS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now if you want to look at the trianed model\n",
        "model = learn.model"
      ],
      "metadata": {
        "id": "bpEva9T1rT1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "7r3ywa4Wr0b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = model.get_submodule('0.model.stem.1')"
      ],
      "metadata": {
        "id": "uP6pDTipsJDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l"
      ],
      "metadata": {
        "id": "WI15X2TpsXCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(l.parameters())"
      ],
      "metadata": {
        "id": "iILo0M-5sXcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How does really a neural networks work\n",
        "A neural network is just a mathematical function. In the most standard kind of neural network, the function:\n",
        "\n",
        "1.   Multiplies each input by a number of values. These values are known as parameters\n",
        "2.   Adds them up for each group of values\n",
        "3.  Replaces the negative numbers with zeros\n",
        "\n",
        "This represents one \"layer\". Then these three steps are repeated, using the outputs of the previous layer as the inputs to the next layer. Initially, the parameters in this function are selected randomly. Therefore a newly created neural network doesn't do anything useful at all -- it's just random!\n",
        "\n",
        "To get the function to \"learn\" to do something useful, we have to change the parameters to make them \"better\" in some way. We do this using gradient descent. Let's see how this works..."
      ],
      "metadata": {
        "id": "chY-TOiYJRDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import title\n",
        "# from ipywidgets import interact\n",
        "from fastai.basics import *\n",
        "\n",
        "# plotting a quadratic line\n",
        "def plotting(f, color='r', min=-2,max=2, Title=None):\n",
        "  x = torch.linspace(min, max, 500)[:,None]\n",
        "  plt.plot(x, f(x), color)\n",
        "  plt.title(Title)\n",
        "  plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "-Lsw6-eWsb1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "  return 3*x**2 + 2*x +1"
      ],
      "metadata": {
        "id": "Tm_y5n7duPEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotting(f,min=-2,max=2)"
      ],
      "metadata": {
        "id": "Kjo6df9nMulp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This quadratic is of the form $ax^2 + bx + c$, with parameters $a=3$, $b=2$, $c=1$.\n",
        "\n",
        "To make it easier to try out different quadratics for fitting a model to the data we'll create, let's create a function that calculates the value of a point on any quadratic:"
      ],
      "metadata": {
        "id": "84B3A-azOyHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quad(a, b, c, x): return a*x**2 + b*x + c\n"
      ],
      "metadata": {
        "id": "FTSxfJKbNAYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## If we fix some particular values of a, b, and c, then we'll have made a quadratic. To fix values passed to a function in python, we use the partial function, like so:\n",
        "\n"
      ],
      "metadata": {
        "id": "Y7UA5_8ePA0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to put this explanation in your notebook:$$\\underbrace{f(a, b, c, x)}_{\\text{General Function}} \\xrightarrow{\\text{partial}(a,b,c)} \\underbrace{f_{a,b,c}(x)}_{\\text{Specialized Function}}$$For example, if you run f = mk_quad(3, 2, 1), then:f(1) is the same as calling quad(3, 2, 1, 1).f(10) is the same as calling quad(3, 2, 1, 10)."
      ],
      "metadata": {
        "id": "FkM4nYk5dSMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mk_quad(a,b,c): return partial(quad, a,b,c)"
      ],
      "metadata": {
        "id": "mYta40dcO8ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## So for instance, we can recreate our previous quadratic:"
      ],
      "metadata": {
        "id": "_v_9jjXhPHKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f2 = mk_quad(3,2,1)\n",
        "plotting(f2)"
      ],
      "metadata": {
        "id": "gBphpr1fPDz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's simulate making some noisy measurements of our quadratic f. We'll then use gradient descent to see if we can recreate the original function from the data.\n",
        "\n",
        "Here's a couple of functions to add some random noise to data:"
      ],
      "metadata": {
        "id": "kRPQ0AM2PodM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def noise(x, scale): return np.random.normal(scale=scale, size=x.shape)\n",
        "def add_noise(x, mult, add): return x * (1+noise(x,mult)) + noise(x,add)"
      ],
      "metadata": {
        "id": "Eiw82Dh8PLM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "x = torch.linspace(-2, 2, steps=20)[:,None]\n",
        "y = add_noise(f(x), 0.15, 1.5)"
      ],
      "metadata": {
        "id": "9rZ3er0RPxzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A link to numpy book [link](https://wesmckinney.com/book/)"
      ],
      "metadata": {
        "id": "GrDmr_XMQJzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x,y)"
      ],
      "metadata": {
        "id": "_-waPp8UPz6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @interact(a=1.1, b=1.1, c=1.1)\n",
        "def plot_quad(a, b, c):\n",
        "    plt.scatter(x,y)\n",
        "    plotting(mk_quad(a,b,c))"
      ],
      "metadata": {
        "id": "wFzZRjlpQa79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mae(preds, acts): return (torch.abs(preds-acts)).mean()\n"
      ],
      "metadata": {
        "id": "TG62Ic8BQmOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @interact(a=1.1, b=1.1, c=1.1)\n",
        "def plot_quad(a, b, c):\n",
        "    f = mk_quad(a,b,c)\n",
        "    plt.scatter(x,y)\n",
        "    loss = mae(f(x), y)\n",
        "    plotting(f,Title = (f'Loss: {loss:.2f}'))"
      ],
      "metadata": {
        "id": "CPxFhegOQzbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Derivatives, which measure the rate of change of a function. Tutorial can be found [here](https://www.youtube.com/playlist?list=PLybg94GvOJ9ELZEe9s2NXTKr41Yedbw7M)"
      ],
      "metadata": {
        "id": "UhwXs5i2Rybd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Define the basic ReLU\n",
        "def relu(x): return torch.clamp(x, min=0.)\n",
        "\n",
        "# 2. Create two different \"neurons\"\n",
        "# Neuron A: Starts at -1.0\n",
        "def neuron_a(x): return relu(x + 1.0)\n",
        "\n",
        "# Neuron B: Starts at 0.5 and is \"flipped\" and steeper\n",
        "def neuron_b(x): return -2.0 * relu(x - 0.5)\n",
        "\n",
        "# 3. The \"Neural Network\" (Adding them together)\n",
        "def neural_net(x): return neuron_a(x) + neuron_b(x)\n",
        "\n",
        "# 4. Plotting the results\n",
        "x = torch.linspace(-2, 2, 100)\n",
        "plt.plot(x, neuron_a(x), '--', label=\"Neuron A\", color='blue')\n",
        "plt.plot(x, neuron_b(x), '--', label=\"Neuron B\", color='green')\n",
        "plt.plot(x, neural_net(x), label=\"Combined Output (The Net)\", color='red', linewidth=3)\n",
        "plt.axhline(0, color='black', lw=1)\n",
        "plt.legend()\n",
        "plt.title(\"How ReLUs Build Shapes\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CrYgGdKAQ2Sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0e-40hbVfCsz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}